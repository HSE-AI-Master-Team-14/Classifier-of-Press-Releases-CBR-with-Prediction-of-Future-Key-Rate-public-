Построение бейзлайна и выбор метрик

Для построяние стартовой точке в гонке была создана Функция предсказания самого частого класса (случайный выбор с распределением весов по меткам классов в  обучающей выборке).
На наших данных функция дала следующее распределение классов:

      0       42 
     -1       30
      1       25
 
Name: count, dtype: int64
 
На всех данных (функция предсказания самого частого класса):
- Accuracy: 0.35051546391752575
- Error rate: 0.6494845360824743


Функция предсказания самого частого класса на test

              precision    recall  f1-score   support

          -1       0.20      0.33      0.25         6
           0       0.44      0.36      0.40        11
           1       0.20      0.14      0.17         7

    accuracy                           0.29        24
    macro avg      0.28      0.28      0.27        24
    weighted avg   0.31      0.29      0.29        24


+
Далее начали гонку.
## Bag of words + LogReg

LogisticRegression() на мешке слов

              precision    recall  f1-score   support

          -1       0.67      0.67      0.67         6
           0       0.64      0.64      0.64        11
           1       0.71      0.71      0.71         7

    accuracy                           0.67        24
    macro avg      0.67      0.67      0.67        24
    weighted avg   0.67      0.67      0.67        24



+

## TF-IDF + LogReg
LogisticRegression() на TF-IDF

              precision    recall  f1-score   support

          -1       0.67      0.67      0.67         6
           0       0.64      0.64      0.64        11
           1       0.71      0.71      0.71         7

    accuracy                           0.67        24
    macro avg      0.67      0.67      0.67        24
    weighted avg   0.67      0.67      0.67        24

+

## N-GRAM BAG OF WORDS + LogReg

LogisticRegression() на N-GRAM BAG OF WORDS

              precision    recall  f1-score   support

          -1       1.00      0.62      0.77         8
           0       0.59      1.00      0.74        10
           1       1.00      0.43      0.60         7

    accuracy                           0.72        25
    macro avg      0.86      0.68      0.70        25
    weighted avg   0.84      0.72      0.71        25

+
## W2V + LogReg

Здесь качество упало

LogisticRegression() на word to vec

              precision    recall  f1-score   support

          -1       0.00      0.00      0.00         8
           0       0.40      1.00      0.57        10
           1       0.00      0.00      0.00         7

    accuracy                           0.40        25
    macro avg      0.13      0.33      0.19        25
    weighted avg   0.16      0.40      0.23        25

+
Создали пайплайн на TF-IDF + LogReg хотя качество на N-GRAM BAG OF WORDS + LogReg получили выше.

В качестве метрик качество использовали classification_report():
1) accuracy 
2) precision 
3) recall
4) f1-score


## Мотивация выбора метрик

1. Accuracy. По сути эта метрика представляет собой долю правильных ответов. В нашем случае нельзя полагаться исключительно на эту метрику, поскольку классы в датасете не слишком сбалансированы: класс 1 — 41 наблюдение, класс -1 — 30 наблюдений, класс 0 — 26 наблюдений. Есть риск, что модель может достичь высокой accuracy, просто предсказывая наиболее распространенный класс. Именно поэтому стоит смотреть на эту метрику в координации с остальными.

2. Precision. Эту метрику мы рассматриваем для каждого класса отдельно. Например, для LogisticRegression() на TF-IDF в пайплайне наибольшее значение precision (0.8) наблюдается для самого распространённого Класса 1. Для самого редкого Класса 0 значение этой метрики равно 0.6, а это значит, что модель стоит улучшить. 

3. Recall. Как и precision, рассматриваем эту метрику для каждого класса отдельно. Высокий recall для означает, что модель эффективно находит большинство наблюдений класса. Так, для LogisticRegression() на TF-IDF в пайплайне значения recall равны значениям precision.

4. F1-score. F1-score — это гармоническое среднее precision и recall. Метрика особенно полезна при несбалансированных данных. Поскольку для LogisticRegression() на TF-IDF в пайплайне precision и recall, то F-мера имеет аналогичные значения. Её можно интерпретировать для каждого класса отдельно, а также использовать взвешенный F1-score, учитывающий размер каждого класса.

Таким образом, в рамках нашего датасета нельзя использовать только accuracy. Чтобы оценить производительность модели, стоит смотреть на совокупность перечисленных метрик.
